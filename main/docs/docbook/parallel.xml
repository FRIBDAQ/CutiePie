<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.3//EN"
                      "file:///usr/share/xml/docbook/schema/dtd/4.5/docbookx.dtd
"
>
<book>
    <bookinfo>
      <title>Parallel SpecTcl (version 6.0-dev)</title>
      <author><firstname>Giordano</firstname><surname>Cerizza</surname></author>
      <revhistory>
          <revision>
             <revnumber>1.0</revnumber>
             <date>February 10, 2020</date>
             <authorinitials>GC</authorinitials>
             <revremark>Original Release</revremark>
          </revision>
      </revhistory>
    </bookinfo>
    <chapter>
        <title>Introduction</title>
        <para>
	  This manual describes the parallel feature of SpecTcl that was introduced in version 6.0. Parallel SpecTcl supports both interactive and offline processing of event files.
	  When run on a multi-core machine, Parallel Spectcl performs multi-threaded unpacking and histogramming being limited only by the I/O throughput.
        </para>
        <para>
	  This document is organized as follows:
        </para>
        <itemizedlist>
            <listitem>
                <para>
		  Brief description of the design pattern and warnings of Parallel SpecTcl.
                </para>
            </listitem>
            <listitem>
                <para>
		  How to prepare to use it (thread-safe skeletons) to steer your analisis pipelines.
                </para>
            </listitem>
            <listitem>
                <para>
		  How to configure Parallel SpecTcl to run over multi-core systems.
                </para>
            </listitem>	    
        </itemizedlist>
        <para>
	  Some notes before diving into the details. Parallel SpecTcl is an extended version of SpecTcl. It parallelizes the analysis pipelines speeding up the unpacking and histogramming process.
	  Just like the normal SpecTcl, to use Parallel SpecTcl you'll need to define and register an analysis pipeline.  The same even processors you use in Spectcl can be used in the parallel
	  alternative, although they have to be setup and implement differently. Thread safety is the principle behind the new implementation. Thread-safe code only manipulates shared data
	  structures in a manner that ensures that all threads behave properly and fulfill their design specifications without unintended interaction. Examples of implementation for VMUSB and DDAS
	  analyses will be provided.
	  Once implemented correctly, set of parameters, spectra, gates and gate applications can be applied just like the normal SpecTcl.
        </para>
    </chapter>
    <chapter>
      <title>Parallel SpecTcl: an introduction</title>
      <para>
	The idea of developing a version of SpecTcl that could take advantage of the now common multi-core machines came from basic need of being able to handle high data rates experiment
	in perspective of the upcoming FRIB era. In alternative to Batch/MPI SpecTcl, which doesn't offer interactivity, Parallel SpecTcl allows to monitor online parameters just like the normal
	SpecTcl. Furthermore, it adds computation flexibility when needed (see later for details on worker-driven load-balancing pattern) and speeds up by order of magnitudes offline analyses
	when recorded files are loaded. The whole phylosophy behind this choice followed the efforts to upgrade the whole DAQ readout/analysis to a more modular and parallel system.
      </para>
      <para>
	To understand how Parallel SpecTcl works, let's schematize how the "normal" SpecTcl works (see Figure 2-1). Underneath SpecTcl, a Tcl loop defines the "time" in which events are analyzed.
	Every second, on an event-by-event base, a buffer of data goes through the SpecTcl analysis engine, is read, unpacked, and histogrammed. What I call engine is a trifecta of C++ classes that
	interact with each other: a buffer decoder, an event unpacker, and an analyzer. Being a single-core application, the processing speed is defined both by the processor itself and the I/O
	throughput. It is possible to analyze up to 100 MB/s of data, with the side note that this number is highly dependent on the complexity of the analysis pipeline. In this version of SpecTcl,
	the Tcl timing loop and the buffer size dictate the analysis and histogramming speed.
	<figure>
	  <title>Schematic representation of the working components of Spectcl 5.</title>
	  <mediaobject>
	    <imageobject>
	      <imagedata fileref="figure1.jpg" format="JPG"/>
	    </imageobject>
	  </mediaobject>
	</figure>
      </para>	
      <para>
	Figure 2-2 shows the working components of Parallel SpecTcl. As one can see, the main components are still the same. A regrouping of the processing operations and the introduction of a "sender"
	determine the work flow. Also, the main noticeable difference is the proliferation of "engine" units. Contrary to SpecTcl, Parallel SpecTcl does not run on a single thread. To be able to run
	an analysis pipeline one needs at least three threads: 1) the main thread that deals with starting the app, attaching the datasource (either online or evt file), and finally histograms
	the spectrum 2) the "sender" thread that handles and sends the events to the worker units 3) the worker unit with the "engine" that performs the analysis.
	Another major different with SpecTcl is the fact that there is not Tcl loop dictating the timing. The whole analysis process is driven by the workers, so the computation speed is
	determined by the disk/memory access to read buffers of data and the number of the worker units instantiated. The average processing speed varies from hundreds of megabytes per second
	to gigabytes per second (if memory caching effects kick in). 
	<figure>
	  <title>Schematic representation of the working components of Parallel Spectcl.</title>
	  <mediaobject>
	    <imageobject>
	      <imagedata fileref="figure2.jpg" format="JPG"/>
	    </imageobject>
	  </mediaobject>
	</figure>
      </para>
      <para>
	The event handling between the sender and the worker units occurs via an asyncronous messaging library (ZeroMQ). The design pattern of choice for the communication is a router-dealer one,
	which allows a worker-driven load-balance between all the workers allocated without wasting computational resources. The router-dealer messaging pattern algorithm is showed in Figure 2-3.
	Each worker unit, when instantiated, sends a "ready" message to the sender. Upon receiving, the sender reads a "chunk" of data (configurable via SpecTclInit.tcl - see later for details),
	formats it as a message, and pushes it to the worker on a first-come-first-served base. Each worker then attaches to the main thread for histogramming. The process goes on until no data is
	available: at this point the sender sends and "end" message to the workers that will automatically shutdown. The elapsed time, the average processing rate, and the total number of processed
	events is displayed in the gui in real time.
	<figure>
	  <title>Schematic representation of router-dealer messaging pattern algorithm.</title>
	  <mediaobject>
	    <imageobject>
	      <imagedata fileref="figure3.jpg" format="JPG"/>
	    </imageobject>
	  </mediaobject>
	</figure>
      </para>
    </chapter>
    <chapter>
      <title>How to create your thread-safe analysis pipeline</title>
      <para>
	Writing multithreading programs is not trivial. Problems like data races (i.e. concurrently writing and reading of data), minimize explicit sharing of writable data (i.e. if you share data,
	it should be constant), and synchronization between tasks are only several of the things to keep in mind. For this reason, I provide two basic skeletons for analysis pipeline
	(one for VMUSB events and one for DDAS built events) to guide the use to a correct way to program for Parallel SpecTcl.
      </para>
      <para>
	To start with, obtain the Parallel SpecTcl skeleton. This consists of the files in the VMUSBSkel (or DDASSkel) directory of the Skeleton installation tree.
	Put these files in an empty directory. For example: suppose SpecTcl is installed in /usr/opt/spectcl/6.0-000,
      </para>
      <section>
	<title>Parallel VMUSBSpecTcl</title>
	<example>
	  <title>Obtaining the Parallel SpecTcl skeleton</title>
	  <programlisting>
	    mkdir parallel
	    cd parallel
	    cp /usr/opt/spectcl/6.0-000/VMUSBSkel/* .
	  </programlisting>
	</example>
	<para>
	  The skeleton consists of several files; Makefile and MySpecTclApp.cpp, CMyProcessor.cpp (which is what you want to modify for your needs) and other files that you won't need to edit.
	</para>
	<para>
	  In editing <filename>MySpecTclApp.cpp</filename>, you need to consider three things:
	</para>
	<itemizedlist>
	  <listitem>
	    <para>
	      The actual event processing pipeline you are going to create.  Note that unlike SpecTcl, all pipeline
	      elements (event processors) must have names. 
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      The name of the shared object the Makefile will create.
	    </para>
	  </listitem>
	</itemizedlist>
	<para>
	  To setup the event processing pipeline you'll need to provide <literal>#include</literal> directives to pull in
	  the headers for your event processors.  Don't specify absolute paths, take care of that in the Makefile.
	</para>
	<para>
	  Here's an example
	</para>
	<example>
	  <title>Including event processor headers</title>
	  <programlisting>
	    ...
	    //  Here you should include your headers for your event processors.
	    
	    #include &lt;CMyProcessor.h&gt;
	    ...
	  </programlisting>
	</example>
	<para>
	  The command shown is in the skeleton to indicate where to put these <literal>#include</literal> directives.
	</para>
	<para>
	  Next, locate the class <classname>MySpecTclApp</classname>, create and register the event processor(s) you need
	  in the order you want them called. For example,
	</para>
	<example>
	  <title>Registering your event processing pipeline</title>
	  <programlisting>
	    ...
	    void
	    CMySpecTclApp::CreateAnalysisPipeline(CAnalyzer& rAnalyzer)
	    {
	      RegisterEventProcessor(*(new CStackUnpacker), "adc-data");
	      RegisterEventProcessor(*(new CMyProcessor), "example");
	    }
	    ...
	  </programlisting>
	</example>
	<para>
	  FYI, CStackUnpacker is the basic unpacking class for VMUSBSpecTcl that has to be defined before any user-defined processor to work correctly. For more information on VMUSBSpecTcl
	  please refer to the corresponding section in the SpecTcl manual.
	</para>
	<para>
	  Now let's see what the CMyProcessor class looks like.
	</para>
	<example>
	  <title>Example of CMyProcessor.h</title>
	  <programlisting>
	    #ifndef CMYPROCESSOR_H
	    #define CMYPROCESSOR_H

	    #include "EventProcessor.h"
	    #include "ThreadAnalyzer.h"
	    #include &lt;Event.h&gt;
	    #include &lt;TreeParameter.h&gt;

	    class CParameterMapper;

	    class CMyProcessor : public  CEventProcessor
	    {
	    public:

	    long var1;  <co id='make.vars' />
	    CTreeParameter pars;
	    CTreeParameter tmp;
	    CTreeVariable vars;

	    CMyProcessor(); <co id='make.ctor' />
	    CMyProcessor(const CMyProcessor&amp; rhs);
	    virtual ~CMyProcessor();
	    virtual CMyProcessor* clone() { return new CMyProcessor(*this); }

	    void setParameterMapper(DAQ::DDAS::CParameterMapper&amp; rParameterMapper){}; <co id='make.map' />

	    virtual Bool_t operator()(const Address_t pEvent, <co id='make.oper' />
	    CEvent&amp;         rEvent,
	    CAnalyzer&amp;      rAnalyzer,
	    CBufferDecoder&amp; rDecoder,
	    BufferTranslator&amp; trans,
	    long thread);

	    virtual Bool_t OnInitialize(); <co id='make.other' />

	    };

	    #endif
	  </programlisting>
	</example>
	<calloutlist>
	  <callout arearefs='make.vars'>
	    <para>
	      In this section the CTreeParameter, CTreeVariable, and support variables are be defined. In the implementation file, one can see how the
	      CTreeParameter tmp is used as copy of another CTreeParameter.
	    </para>
	  </callout>
	  <callout arearefs='make.ctor'>
	    <para>
	      This is a very important part of the thread-safe code for the processor. We need an explicit declaration of the class constructor, copy constructor, destructor, and clone method.
	      If one does NOT implement correctly the class, failure will occur at compilation time.
	    </para>
	  </callout>
	  <callout arearefs='make.map'>
	    <para>
	      Although there is no explicit mapping declaration inside CreatePipelineAnalysis for VMUSBSpecTcl, this declaration is fundamental for the compilation of the code. For more details on
	      the reason of its importance, come to my office and I'll explain it to you (hint: implementation of a method for a pure virtual function).  
	    </para>
	  </callout>
	  <callout arearefs='make.oper'>
	    <para>
	      If compared to normal SpecTcl, the function operator requires extra arguments to for the proper definition of our multithreading program.
	    </para>
	  </callout>
	  <callout arearefs='make.other'>
	    <para>
	      These are the classic method that SpecTcl offers OnInitialize, OnBegin, OnEnd... It's up to the user knowing if the analysis code needs them or not.
	    </para>
	  </callout>	  
	</calloutlist>
	<example>
	  <title>Example of CMyProcessor.cpp</title>
	  <programlisting>
	    #include "CMyProcessor.h"
	    #include &lt;CRingBufferDecoder.h&gt;
	    #include &lt;SpecTcl.h&gt;
	    #include &lt;sstream&gt;
	    #include &lt;iomanip&gt;
	    #include &lt;cmath&gt;

	    CMyProcessor::CMyProcessor():
	    var1(0)
	    {}

	    CMyProcessor::CMyProcessor(const CMyProcessor&amp; rhs):
	    var1(rhs.var1)
	    {}

	    CMyProcessor::~CMyProcessor()
	    {}

	    Bool_t
	    CMyProcessor::operator()(const Address_t pEvent,
	    CEvent&amp;         rEvent,
	    CAnalyzer&amp;      rAnalyzer,
	    CBufferDecoder&amp; rDecoder,
	    BufferTranslator&amp; trans,
	    long thread)
	    {
	    if (tmp.isValid()){  <co id='make.ex' />

	    pars = tmp + vars*var1;

	    }

	    return kfTRUE;
	    }

	    Bool_t
	    CMyProcessor::OnInitialize() <co id='make.oninit' />
	    {
	    tmp.Initialize("adc1.06");
	    pars.Initialize("test_var", 16384, 0.0, 16383.0, "");
	    vars.Initialize("const", 10, "");
	    if (!tmp.isBound())
	    tmp.Bind();
	    if (!pars.isBound())
	    pars.Bind();

	    return kfTRUE;
	    }
          </programlisting>
	</example>
	<calloutlist>
	  <callout arearefs='make.ex'>
	    <para>
	      A simple example of parameter calibration based on a previously defined CTreeParameter (tmp), CTreeVariable (vars), and a long variable (var1).
	    </para>
	  </callout>
	  <callout arearefs='make.oninit'>
	    <para>
	      After the Parallel SpecTcl app is built and started, a few CTreeParameter and CTreeVariable are initialized. To make the example complete, we initialized tmp
	      as a copy of the CTreeParameter associated to the ADC channel number 6, pars as a new CTreeParameter that will correspond to some calibrated quantity, and vars
	      as a CTreeVariable for the calibration process. Note that the two defined new CTreeParameter are bound at this stage as well. 
	    </para>
	  </callout>	  
	</calloutlist>
	<para>
	  Once you've edited everything, use make to build the shared object and don't forget to add it to the Makefile.
	</para>
	<para>
	  NB: If you have a more complex structure for your calibration parameters please look at the DDASSkel example for more details.
	</para>
      </section>

      <section>
	<title>Parallel DDASSpecTcl</title>
	<example>
	  <title>Obtaining the Parallel SpecTcl skeleton</title>
	  <programlisting>
	    mkdir parallel
	    cd parallel
	    cp /usr/opt/spectcl/6.0-000/DDASSkel/* .
	  </programlisting>
	</example>
	<para>
	  The skeleton consists of several files. The example has been created following the model of analysis pipeline of the one existing experiments. 
	</para>
	<itemizedlist>
	  <listitem>
	    <para>
	      Makefile: the user needs to add the *.o of the event processor that he created. 
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      MySpecTclapp: class to create and register the event processor(s) you need in the order you want them called. NB global static definitions are forbidden (more later).
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      MyParameterMapper: this file doesn't need to be edited.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      MyParameters: class that contains the main data structure. In the example provided it contains several nested structures (ChannelData, CTreeParameter, MyPipelineData, MyParameters2).
	      In Figure 3-1, a schematic representation of the structure is showed.
	      <figure>
		<title>Schematic representation of the working components of Spectcl 5.</title>
		<mediaobject>
		  <imageobject>
		    <imagedata fileref="figure4.jpg" format="JPG" scale="50"/>
		  </imageobject>
		</mediaobject>
	      </figure>
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      MyCalibrator: class that contains the user-defined event processor. NB: the structure of the class is thread-safe any modification may cause into segmentation faults and/or memory leaks.
	    </para>
	  </listitem>	  	  
	</itemizedlist>
	<para>
	  In editing <filename>MySpecTclApp.cpp</filename>, you need to consider three things:
	</para>
	<itemizedlist>
	  <listitem>
	    <para>
	      The actual event processing pipeline you are going to create.  Note that unlike SpecTcl, all pipeline
	      elements (event processors) must have names.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      The name of the shared object the Makefile will create.
	    </para>
	  </listitem>
	</itemizedlist>
	<para>
	  To setup the event processing pipeline you'll need to provide <literal>#include</literal> directives to pull in
	  the headers for your event processors.  Don't specify absolute paths, take care of that in the Makefile.
	</para>
	<para>
	  Here's an example
	</para>
	<example>
	  <title>Including event processor headers</title>
	  <programlisting>
	    ...
	    //  Here you should include your headers for your event processors.

	    #include &lt;MyCalibrator.h&gt;
	    ...
	  </programlisting>
	</example>
	<para>
	  The command shown is in the skeleton to indicate where to put these <literal>#include</literal> directives.
	</para>
	<para>
	  Next, locate the class <classname>MySpecTclApp</classname>, create and register the event processor(s) you need
	  in the order you want them called. For example,
	</para>
	<example>
	  <title>Registering MyParameters, MyParameterMapper, and the processing pipeline</title>
	  <programlisting>
	    void
	    CMySpecTclApp::CreateAnalysisPipeline(CAnalyzer&amp; rAnalyzer)
	    {
	    MyParameters* pParams = new MyParameters("ddas");
	    MyParameterMapper* pMapper = new MyParameterMapper(*pParams);
	    RegisterData(pMapper);
	    RegisterEventProcessor(*(new DAQ::DDAS::CDDASBuiltUnpacker({1, 2, 3 })), "Raw");
	    RegisterEventProcessor(*(new MyCalibrator()), "Cal");
	    }
	  </programlisting>	
	</example>
	<para>
	  It is fundamental to notice how objects are declared and dynamically created. Global static object are forbidden by multithreading programming. Local static object are good.
	  Declaring any of those objects without initialization outside CMySpecTclApp::CreateAnalysisPipeline would cause undefined behaviors.
	</para>
	<para>
	  Let's look now at the MyParameters definition.
	  <example>
	    <title>Definition of MyParameters.h</title>
	    <programlisting>
	      #ifndef MYPARAMETERS_H
	      #define MYPARAMETERS_H

	      #include &lt;config.h&gt;
	      #include &lt;TreeParameter.h&gt;
	      #include &lt;string&gt;
	      #include &lt;PipelineData.h&gt;
	      #include &lt;vector&gt;
	      #include "MyPipelineData.h"
	      #include "MyParameters2.h"

	      struct ChannelData {

	      CTreeParameter energy;
	      CTreeParameter timestamp;

	      // Initialize the TreeParameters
	      //
	      // We will create TreeParameters with names associated with
	      // the name passed in. For example, if name = "rawdata", then
	      // we will create TreeParameters with names rawdata.energy and
	      // rawdata.timestamp.
	      //
	      // \param name  name of parent in tree structure

	      ChannelData();
	      ChannelData(const ChannelData&amp; rhs);
	      void Initialize(std::string name);
	      void Reset();
	      };

	      //____________________________________________________________
	      // Struct for top-level events
	      //
	      struct MyParameters {

	      ChannelData      chan[1000];
	      CTreeParameter   multiplicity;
	      MyPipelineData   data;
	      MyParameters2    example;

	      // Ctor
	      MyParameters(std::string name);
	      // Dtor
	      ~MyParameters(){};
	      // Copy Ctor
	      MyParameters(const MyParameters&amp; rhs);

	      void Reset();
	      };
	      #endif
	    </programlisting>
	  </example>
	  The most important part is the copy constructor for every structure or class we will define. This ensures that objects are correctly copied for each thread we will instantiate.
	  MyPipelineData is a special structure that contains STL vectors. I highly suggest to keep these separated from the CTreeParameters. Nesting classes in a logical data structure
	  according to tasks is a good approach for multithreading programming. Similar structure constructions can be observed for MyPipelineData and MyParameters2.
	</para>
	<para>
	  The core of your analysis pipeline is your MyCalibrator. Let's look at it more in details:
	  <example>
	    <title>Definition of MyCalibrator.h</title>
	    <programlisting>
	      #ifndef __MYCALIBRATOR_H
	      #define __MYCALIBRATOR_H

	      #include &lt;EventProcessor.h&gt;
	      #include &lt;TranslatorPointer.h&gt;
	      #include &lt;TCLAnalyzer.h&gt;

	      class MyParameterMapper;

	      class MyCalibrator : public  CEventProcessor
	      {
	      public:
	      MyParameterMapper* m_pParameterMapper; <co id='make.dpmap' />

	      MyCalibrator(); <co id='make.dctor' />
	      MyCalibrator(const MyCalibrator&amp; rhs);
	      ~MyCalibrator();
	      virtual MyCalibrator* clone() { return new MyCalibrator(*this); }

	      void setParameterMapper(DAQ::DDAS::CParameterMapper&amp; rParameterMapper); <co id='make.dsetmap' />

	      virtual Bool_t operator()(const Address_t pEvent,  <co id='make.doper' />
	      CEvent&amp;         rEvent,
	      CAnalyzer&amp;      rAnalyzer,
	      CBufferDecoder&amp; rDecoder,
	      BufferTranslator&amp; trans,
	      long thread);
	      };
	      #endif
	    </programlisting>
	  </example>
	  <calloutlist>
	    <callout arearefs='make.dpmap'>
	      <para>
		MyParameterMapper is the common interface class that handles the mapping between channels and data structure.
		Just for information, here the definition of the public members:
		<example>
		  <title>Definition of MyParameterMapper.h</title>
		  <programlisting>
		    ...
		    class MyParameterMapper : public DAQ::DDAS::CParameterMapper
		    {
		    public:
		    
		    MyParameters  m_params;           // reference to the tree parameter structure
		    std::map&lt;int, int&gt; m_chanMap;     // global channel index for crates
		    ...
		  </programlisting>
		</example>
		As descibed above, this file doesn't need to be modified.
	      </para>
	    </callout>
	    <callout arearefs='make.dctor'>
	      <para>
		This is a very important part of the thread-safe code for the processor. We need an explicit declaration of the class constructor, copy constructor, destructor,
		and clone method. If one does NOT implement correctly the class, failure will occur at compilation time.
	      </para>
	    </callout>
	    <callout arearefs='make.dsetmap'>
	      <para>
		The registration and setting of the parameter mapping is crucial for the success of Parallel SpecTcl. 
	      </para>
	    </callout>
	    <callout arearefs='make.doper'>
	      <para>
		If compared to normal SpecTcl, the function operator requires extra arguments to for the proper definition of our multithreading program.
	      </para>
	    </callout>	    
	  </calloutlist>
	</para>	  
	<para>
	  For the implementation of MyCalibrator class:
	  <example>
	    <title>Definition of MyCalibrator.cpp</title>
	    <programlisting>
	      #include &lt;ThreadAnalyzer.h&gt;
	      #include "MyCalibrator.h"
	      #include "MyParameterMapper.h"
	      #include "MyParameters.h"
	      #include &lt;ZMQRDPatternClass.h&gt;

	      MyCalibrator::MyCalibrator()
	      {}

	      MyCalibrator::MyCalibrator(const MyCalibrator&amp; rhs)
	      {}

	      MyCalibrator::~MyCalibrator() {
	       delete m_pParameterMapper;
	      }

	      void
	      MyCalibrator::setParameterMapper(DAQ::DDAS::CParameterMapper&amp; rParameterMapper) <co id='make.canonic' />
	      {
	       m_pParameterMapper = reinterpret_cast&lt;MyParameterMapper*&gt;(&amp;rParameterMapper);
	      }

	      Bool_t
	      MyCalibrator::operator()(const Address_t pEvent,
	      CEvent&amp;         rEvent,
	      CAnalyzer&amp;      rAnalyzer,
	      CBufferDecoder&amp; rDecoder,
	      BufferTranslator&amp; trans,
	      long thread)
	      {
	       auto&amp; params = m_pParameterMapper->m_params; <co id='make.params' />

	       // loop over hits
	       for(int i= 0; i&lt;params.data.m_chanHit.size(); i++){   <co id='make.loop' />

 	          int id = params.data.m_chanHit[i];
	          double ran = ( static_cast&lt;double&gt;(rand())) / (static_cast&lt;double&gt;(RAND_MAX));

    	          if( id == 341) {   
	           if (rEvent[params.chan[id].energy.getId()].isValid()){
	           params.example.ex1.energy = (params.chan[id].energy + ran) + 0.0;
	           params.example.ex1.ecal = params.example.ex1.energy*params.example.var.var1.c1; 
	          }
	          if (rEvent[params.chan[id].timestamp.getId()].isValid()) 
	           params.example.ex1.time = params.chan[id].timestamp + 10.0;
	         }
      	       }
	       return kfTRUE;
	      };
	    </programlisting>
	  </example>
	  <calloutlist>
	    <callout arearefs='make.canonic'>
	      <para>
		The four canonical constructor, destructor, copy constructor, and clone methods have to be standard for every event processor an user wants to define.
		The setParameterMapper definition is fundamental for the correct copy of the parameter mapper to each worker thread.
	      </para>
	    </callout>
	    <callout arearefs='make.params'>
	      <para>
		This line dictates your entry point to access the data structure you defined in MyParameters.h. Your params object is the top tree of your nested structure.
		If ones looks back at Figure 3-1, can see the actual structure and how to access each component (in red).
	      </para>
	    </callout>
	    <callout arearefs='make.loop'>
	      <para>
		Example of simple loop over hits. This is pretty self explanatory. One can see how the data structure has been linearized to access the members.
	      </para>
	    </callout>
	  </calloutlist>
	</para>	
	<para>
	  Once you've edited everything, use make to build the shared object and don't forget to add it to the Makefile.
	</para>
      </section>
    </chapter>
    <chapter>
      <title>How to configure Parallel SpecTcl</title>
      <para>
	The configuration of Parallel SpecTcl is limited to two new parameters defined in SpecTclInit.tcl.	
	<itemizedlist>
	  <listitem>
	    <para>
	      NumberOfThreads: this parameter sets the number of thread that will be instantiated at startup time. Important to notice that allocating a high number of threads does not mean
	      booking them for as long as they are needed. The number of active threads depends on the I/O data throughput.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      DataChunkSize: this parameter defined the amount of data each worker unit has to analyze. The value to set depends on the triggering data rate or the reading speed from storage.
	      Typical values are 4,8, or 16 MB. 
	    </para>
	  </listitem>
	</itemizedlist>
	<figure>
	  <title>Screenshot of SpecTclInit.tcl</title>
	  <mediaobject>
	    <imageobject>
	      <imagedata fileref="figure5.jpg" format="JPG" scale="50"/>
	    </imageobject>
	  </mediaobject>
	</figure>
	<figure>
	  <title>Screenshot of Parallel SpecTcl frontend GUI</title>
	  <mediaobject>
	    <imageobject>
	      <imagedata fileref="figure6.jpg" format="JPG" scale="50"/>
	    </imageobject>
	  </mediaobject>
	</figure>	
      </para>
    </chapter>        
</book>

